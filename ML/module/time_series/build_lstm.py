# Построить модель

# Вот архитектура модели, которую вы будете использовать. Он очень похож на последний построенный вами RNN, но со слоем Conv1D на входе. Одним из важных аргументов здесь является padding. Для данных временных рядов рекомендуется не допускать, чтобы вычисления для определенного временного шага влияли на значения в будущем. Вот один из способов взглянуть на это:

#     Допустим, у вас есть небольшое окно временного ряда со следующими значениями: [1, 2, 3, 4, 5]. Это означает значение 1Я сидел t=0, 2Я сидел t=1, и т. д.
#     Если у вас есть одномерное ядро ​​размером 3, то первая свертка будет для значений в [1, 2, 3]которые являются значениями для t=0к t=2.
#     Когда вы передаете это на первый временной шаг LSTMпосле свертки это означает, что значение в t=0LSTM зависит от t=1и t=2которые являются ценностями в будущем.
#     Для данных временных рядов вы хотите, чтобы вычисления зависели только от текущего и предыдущего временных шагов.
#     Один из способов сделать это — дополнить массив в зависимости от размера ядра и шага. Для размера ядра 3 и шага 1 окно может быть дополнено следующим образом: [0, 0, 1, 2, 3, 4, 5]. 1все еще в t=0и два нуля добавляются для имитации значений в прошлом.
#     Таким образом, первый шаг будет в [0, 0, 1]и это не содержит никаких будущих значений, когда оно передается последующим уровням.

# Reset states generated by Keras
tf.keras.backend.clear_session()

# Build the model
model = tf.keras.models.Sequential([
  tf.keras.layers.Conv1D(filters=64, kernel_size=3,
                      strides=1, padding="causal",
                      activation="relu",
                      input_shape=[window_size, 1]),
  tf.keras.layers.LSTM(64, return_sequences=True),
  tf.keras.layers.LSTM(64),
  tf.keras.layers.Dense(1),
  tf.keras.layers.Lambda(lambda x: x * 400)
])

# Print the model summary
model.summary()


# Build the Model
model_tune = tf.keras.models.Sequential([
  tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),
                      input_shape=[window_size]),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),
  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),
  tf.keras.layers.Dense(1),
  tf.keras.layers.Lambda(lambda x: x * 100.0)
])

# Print the model summary
model_tune.summary()